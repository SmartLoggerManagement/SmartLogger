<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=edge"/>
<title>Test results - Class MainTest</title>
<link href="../css/base-style.css" rel="stylesheet" type="text/css"/>
<link href="../css/style.css" rel="stylesheet" type="text/css"/>
<script src="../js/report.js" type="text/javascript"></script>
</head>
<body>
<div id="content">
<h1>Class MainTest</h1>
<div class="breadcrumbs">
<a href="../index.html">all</a> &gt; 
<a href="../packages/default-package.html">default-package</a> &gt; MainTest</div>
<div id="summary">
<table>
<tr>
<td>
<div class="summaryGroup">
<table>
<tr>
<td>
<div class="infoBox" id="tests">
<div class="counter">1</div>
<p>tests</p>
</div>
</td>
<td>
<div class="infoBox" id="failures">
<div class="counter">0</div>
<p>failures</p>
</div>
</td>
<td>
<div class="infoBox" id="ignored">
<div class="counter">0</div>
<p>ignored</p>
</div>
</td>
<td>
<div class="infoBox" id="duration">
<div class="counter">29.065s</div>
<p>duration</p>
</div>
</td>
</tr>
</table>
</div>
</td>
<td>
<div class="infoBox success" id="successRate">
<div class="percent">100%</div>
<p>successful</p>
</div>
</td>
</tr>
</table>
</div>
<div id="tabs">
<ul class="tabLinks">
<li>
<a href="#tab0">Tests</a>
</li>
<li>
<a href="#tab1">Standard output</a>
</li>
<li>
<a href="#tab2">Standard error</a>
</li>
</ul>
<div id="tab0" class="tab">
<h2>Tests</h2>
<table>
<thead>
<tr>
<th>Test</th>
<th>Duration</th>
<th>Result</th>
</tr>
</thead>
<tr>
<td class="success">test normal behavior</td>
<td>29.065s</td>
<td class="success">passed</td>
</tr>
</table>
</div>
<div id="tab1" class="tab">
<h2>Standard output</h2>
<span class="code">
<pre>Je suis dans Alerter : Serveur 1 : Tue 7 March 14:50:39 CET 2017 : Temperature = 85Â°C 

DEBUG: setDebug: JavaMail version 1.4.7
before sending
DEBUG: getProvider() returning javax.mail.Provider[TRANSPORT,smtp,com.sun.mail.smtp.SMTPTransport,Oracle]
DEBUG SMTP: useEhlo true, useAuth true
DEBUG SMTP: useEhlo true, useAuth true
DEBUG SMTP: trying to connect to host &quot;smtp.gmail.com&quot;, port 587, isSSL false
220 smtp.gmail.com ESMTP 53sm1667924wrt.52 - gsmtp
DEBUG SMTP: connected to host &quot;smtp.gmail.com&quot;, port: 587

EHLO TheCodingLaptop
250-smtp.gmail.com at your service, [193.52.159.57]
250-SIZE 35882577
250-8BITMIME
250-STARTTLS
250-ENHANCEDSTATUSCODES
250-PIPELINING
250-CHUNKING
250 SMTPUTF8
DEBUG SMTP: Found extension &quot;SIZE&quot;, arg &quot;35882577&quot;
DEBUG SMTP: Found extension &quot;8BITMIME&quot;, arg &quot;&quot;
DEBUG SMTP: Found extension &quot;STARTTLS&quot;, arg &quot;&quot;
DEBUG SMTP: Found extension &quot;ENHANCEDSTATUSCODES&quot;, arg &quot;&quot;
DEBUG SMTP: Found extension &quot;PIPELINING&quot;, arg &quot;&quot;
DEBUG SMTP: Found extension &quot;CHUNKING&quot;, arg &quot;&quot;
DEBUG SMTP: Found extension &quot;SMTPUTF8&quot;, arg &quot;&quot;
STARTTLS
220 2.0.0 Ready to start TLS
EHLO TheCodingLaptop
250-smtp.gmail.com at your service, [193.52.159.57]
250-SIZE 35882577
250-8BITMIME
250-AUTH LOGIN PLAIN XOAUTH2 PLAIN-CLIENTTOKEN OAUTHBEARER XOAUTH
250-ENHANCEDSTATUSCODES
250-PIPELINING
250-CHUNKING
250 SMTPUTF8
DEBUG SMTP: Found extension &quot;SIZE&quot;, arg &quot;35882577&quot;
DEBUG SMTP: Found extension &quot;8BITMIME&quot;, arg &quot;&quot;
DEBUG SMTP: Found extension &quot;AUTH&quot;, arg &quot;LOGIN PLAIN XOAUTH2 PLAIN-CLIENTTOKEN OAUTHBEARER XOAUTH&quot;
DEBUG SMTP: Found extension &quot;ENHANCEDSTATUSCODES&quot;, arg &quot;&quot;
DEBUG SMTP: Found extension &quot;PIPELINING&quot;, arg &quot;&quot;
DEBUG SMTP: Found extension &quot;CHUNKING&quot;, arg &quot;&quot;
DEBUG SMTP: Found extension &quot;SMTPUTF8&quot;, arg &quot;&quot;
DEBUG SMTP: Attempt to authenticate using mechanisms: LOGIN PLAIN DIGEST-MD5 NTLM 
DEBUG SMTP: AUTH LOGIN command trace suppressed
DEBUG SMTP: AUTH LOGIN succeeded
DEBUG SMTP: use8bit false
MAIL FROM:&lt;smartlogger@saagie.com&gt;
250 2.1.0 OK 53sm1667924wrt.52 - gsmtp
RCPT TO:&lt;gregoire.pommier@etu.univ-rouen.fr&gt;
250 2.1.5 OK 53sm1667924wrt.52 - gsmtp
RCPT TO:&lt;nic.gille@gmail.com&gt;
250 2.1.5 OK 53sm1667924wrt.52 - gsmtp
RCPT TO:&lt;franck.caron76@gmail.com&gt;
250 2.1.5 OK 53sm1667924wrt.52 - gsmtp
DEBUG SMTP: Verified Addresses
DEBUG SMTP:   gregoire.pommier@etu.univ-rouen.fr
DEBUG SMTP:   nic.gille@gmail.com
DEBUG SMTP:   franck.caron76@gmail.com
DATA
354  Go ahead 53sm1667924wrt.52 - gsmtp
Date: Fri, 10 Mar 2017 09:38:01 +0100 (CET)
From: smartlogger@saagie.com
To: gregoire.pommier@etu.univ-rouen.fr, nic.gille@gmail.com, 
	franck.caron76@gmail.com
Message-ID: &lt;949962914.1.1489135081551.JavaMail.franck@TheCodingLaptop&gt;
Subject: Alerte !
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Serveur 1 : Tue 7 March 14:50:39 CET 2017 : Temperature =3D 85=C2=B0C=20
.
250 2.0.0 OK 1489135083 53sm1667924wrt.52 - gsmtp
QUIT
221 2.0.0 closing connection 53sm1667924wrt.52 - gsmtp
See mailbox
</pre>
</span>
</div>
<div id="tab2" class="tab">
<h2>Standard error</h2>
<span class="code">
<pre>Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/03/10 09:37:45 INFO SparkContext: Running Spark version 2.1.0
17/03/10 09:37:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/03/10 09:37:45 WARN Utils: Your hostname, TheCodingLaptop resolves to a loopback address: 127.0.1.1; using 10.0.104.191 instead (on interface wlan0)
17/03/10 09:37:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
17/03/10 09:37:45 INFO SecurityManager: Changing view acls to: franck
17/03/10 09:37:45 INFO SecurityManager: Changing modify acls to: franck
17/03/10 09:37:45 INFO SecurityManager: Changing view acls groups to: 
17/03/10 09:37:45 INFO SecurityManager: Changing modify acls groups to: 
17/03/10 09:37:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(franck); groups with view permissions: Set(); users  with modify permissions: Set(franck); groups with modify permissions: Set()
17/03/10 09:37:45 INFO Utils: Successfully started service 'sparkDriver' on port 41997.
17/03/10 09:37:45 INFO SparkEnv: Registering MapOutputTracker
17/03/10 09:37:45 INFO SparkEnv: Registering BlockManagerMaster
17/03/10 09:37:45 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/03/10 09:37:45 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/03/10 09:37:45 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-121eff5b-68b3-48d4-b26b-f2953c48c3cd
17/03/10 09:37:45 INFO MemoryStore: MemoryStore started with capacity 875.1 MB
17/03/10 09:37:45 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/10 09:37:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/03/10 09:37:46 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.0.104.191:4040
17/03/10 09:37:46 INFO Executor: Starting executor ID driver on host localhost
17/03/10 09:37:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56595.
17/03/10 09:37:46 INFO NettyBlockTransferService: Server created on 10.0.104.191:56595
17/03/10 09:37:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/03/10 09:37:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.104.191, 56595, None)
17/03/10 09:37:46 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.104.191:56595 with 875.1 MB RAM, BlockManagerId(driver, 10.0.104.191, 56595, None)
17/03/10 09:37:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.104.191, 56595, None)
17/03/10 09:37:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.104.191, 56595, None)
17/03/10 09:37:46 INFO SharedState: Warehouse path is 'file:/home/franck/Documents/FAC/SmartLoggerManagement/SmartLogger/smartlogger/spark-warehouse'.
17/03/10 09:37:48 INFO CodeGenerator: Code generated in 180.921686 ms
17/03/10 09:37:48 INFO CodeGenerator: Code generated in 21.010242 ms
17/03/10 09:37:48 INFO CodeGenerator: Code generated in 10.219156 ms
17/03/10 09:37:48 INFO ContextCleaner: Cleaned accumulator 0
17/03/10 09:37:48 INFO SparkContext: Starting job: take at Classifier.scala:111
17/03/10 09:37:48 INFO DAGScheduler: Registering RDD 3 (take at Classifier.scala:111)
17/03/10 09:37:48 INFO DAGScheduler: Got job 0 (take at Classifier.scala:111) with 1 output partitions
17/03/10 09:37:48 INFO DAGScheduler: Final stage: ResultStage 1 (take at Classifier.scala:111)
17/03/10 09:37:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/10 09:37:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/10 09:37:48 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at take at Classifier.scala:111), which has no missing parents
17/03/10 09:37:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.1 KB, free 875.1 MB)
17/03/10 09:37:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.3 KB, free 875.1 MB)
17/03/10 09:37:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.104.191:56595 (size: 4.3 KB, free: 875.1 MB)
17/03/10 09:37:49 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/03/10 09:37:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at take at Classifier.scala:111)
17/03/10 09:37:49 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/03/10 09:37:49 WARN TaskSetManager: Stage 0 contains a task of very large size (328 KB). The maximum recommended task size is 100 KB.
17/03/10 09:37:49 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 336033 bytes)
17/03/10 09:37:49 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/10 09:37:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1809 bytes result sent to driver
17/03/10 09:37:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 158 ms on localhost (executor driver) (1/1)
17/03/10 09:37:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/10 09:37:49 INFO DAGScheduler: ShuffleMapStage 0 (take at Classifier.scala:111) finished in 0,167 s
17/03/10 09:37:49 INFO DAGScheduler: looking for newly runnable stages
17/03/10 09:37:49 INFO DAGScheduler: running: Set()
17/03/10 09:37:49 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/10 09:37:49 INFO DAGScheduler: failed: Set()
17/03/10 09:37:49 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at take at Classifier.scala:111), which has no missing parents
17/03/10 09:37:49 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.2 KB, free 875.1 MB)
17/03/10 09:37:49 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 875.1 MB)
17/03/10 09:37:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.104.191:56595 (size: 3.8 KB, free: 875.1 MB)
17/03/10 09:37:49 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/03/10 09:37:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at take at Classifier.scala:111)
17/03/10 09:37:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/03/10 09:37:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 5800 bytes)
17/03/10 09:37:49 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/03/10 09:37:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/10 09:37:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
17/03/10 09:37:49 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2011 bytes result sent to driver
17/03/10 09:37:49 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 25 ms on localhost (executor driver) (1/1)
17/03/10 09:37:49 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/10 09:37:49 INFO DAGScheduler: ResultStage 1 (take at Classifier.scala:111) finished in 0,027 s
17/03/10 09:37:49 INFO DAGScheduler: Job 0 finished: take at Classifier.scala:111, took 0,358665 s
17/03/10 09:37:49 INFO CodeGenerator: Code generated in 6.374336 ms
17/03/10 09:37:49 INFO NaiveBayes: org.apache.spark.ml.classification.NaiveBayes inferred 3 classes for labelCol=nb_0c7588e913fc__labelCol since numClasses was not specified in the column metadata.
17/03/10 09:37:49 INFO CodeGenerator: Code generated in 13.969484 ms
17/03/10 09:37:49 INFO CodeGenerator: Code generated in 7.016091 ms
17/03/10 09:37:49 INFO CodeGenerator: Code generated in 11.969599 ms
17/03/10 09:37:50 INFO SparkContext: Starting job: collect at NaiveBayes.scala:171
17/03/10 09:37:50 INFO DAGScheduler: Registering RDD 11 (map at NaiveBayes.scala:159)
17/03/10 09:37:50 INFO DAGScheduler: Got job 1 (collect at NaiveBayes.scala:171) with 1 output partitions
17/03/10 09:37:50 INFO DAGScheduler: Final stage: ResultStage 3 (collect at NaiveBayes.scala:171)
17/03/10 09:37:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/03/10 09:37:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/03/10 09:37:50 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at map at NaiveBayes.scala:159), which has no missing parents
17/03/10 09:37:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.6 MB, free 869.4 MB)
17/03/10 09:37:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 385.0 KB, free 869.1 MB)
17/03/10 09:37:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.104.191:56595 (size: 385.0 KB, free: 874.7 MB)
17/03/10 09:37:50 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/03/10 09:37:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at map at NaiveBayes.scala:159)
17/03/10 09:37:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/03/10 09:37:50 WARN TaskSetManager: Stage 2 contains a task of very large size (2612 KB). The maximum recommended task size is 100 KB.
17/03/10 09:37:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 2675607 bytes)
17/03/10 09:37:50 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/03/10 09:37:50 INFO CodeGenerator: Code generated in 8.270534 ms
17/03/10 09:37:50 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1709 bytes result sent to driver
17/03/10 09:37:50 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 163 ms on localhost (executor driver) (1/1)
17/03/10 09:37:50 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/10 09:37:50 INFO DAGScheduler: ShuffleMapStage 2 (map at NaiveBayes.scala:159) finished in 0,163 s
17/03/10 09:37:50 INFO DAGScheduler: looking for newly runnable stages
17/03/10 09:37:50 INFO DAGScheduler: running: Set()
17/03/10 09:37:50 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/03/10 09:37:50 INFO DAGScheduler: failed: Set()
17/03/10 09:37:50 INFO DAGScheduler: Submitting ResultStage 3 (ShuffledRDD[12] at aggregateByKey at NaiveBayes.scala:160), which has no missing parents
17/03/10 09:37:50 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 5.6 MB, free 863.4 MB)
17/03/10 09:37:50 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 386.1 KB, free 863.1 MB)
17/03/10 09:37:50 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.104.191:56595 (size: 386.1 KB, free: 874.3 MB)
17/03/10 09:37:50 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/03/10 09:37:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (ShuffledRDD[12] at aggregateByKey at NaiveBayes.scala:160)
17/03/10 09:37:50 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/03/10 09:37:50 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, ANY, 5765 bytes)
17/03/10 09:37:50 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/03/10 09:37:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/10 09:37:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/10 09:37:50 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 26504 bytes result sent to driver
17/03/10 09:37:50 INFO ContextCleaner: Cleaned accumulator 109
17/03/10 09:37:50 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 104 ms on localhost (executor driver) (1/1)
17/03/10 09:37:50 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/10 09:37:50 INFO DAGScheduler: ResultStage 3 (collect at NaiveBayes.scala:171) finished in 0,105 s
17/03/10 09:37:50 INFO DAGScheduler: Job 1 finished: collect at NaiveBayes.scala:171, took 0,437287 s
17/03/10 09:37:50 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.0.104.191:56595 in memory (size: 4.3 KB, free: 874.3 MB)
17/03/10 09:37:50 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.104.191:56595 in memory (size: 3.8 KB, free: 874.3 MB)
17/03/10 09:37:50 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.0.104.191:56595 in memory (size: 385.0 KB, free: 874.7 MB)
17/03/10 09:37:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/03/10 09:38:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/03/10 09:38:01 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
17/03/10 09:38:01 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
17/03/10 09:38:01 INFO CodeGenerator: Code generated in 6.756175 ms
17/03/10 09:38:01 INFO CodeGenerator: Code generated in 6.683787 ms
17/03/10 09:38:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
</pre>
</span>
</div>
</div>
<div id="footer">
<p>
<div>
<label class="hidden" id="label-for-line-wrapping-toggle" for="line-wrapping-toggle">Wrap lines
<input id="line-wrapping-toggle" type="checkbox" autocomplete="off"/>
</label>
</div>Generated by 
<a href="http://www.gradle.org">Gradle 3.3</a> at 10 mars 2017 09:38:48</p>
</div>
</div>
</body>
</html>
